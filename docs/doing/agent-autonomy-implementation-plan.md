# AIエージェント自律性・連携機能 実装計画（v2）

## 📋 概要

現状の「プロンプトテンプレート + LLM 一方通行呼び出し」パターンを、
AIエージェントの定義を満たすアーキテクチャに進化させる。

### AIエージェントの4要素と本プロジェクトでの実現方法

| 要素 | 定義 | 本プロジェクトでの実現 |
|------|------|----------------------|
| 自律的な判断 | 与えられた情報から自分で次のアクションを決める | オーケストレーターが expertise/cannotHandle を参照して動的に判断 |
| ツール使用 | 外部リソースを自分で呼び出す | エキスパートが「追加情報が必要」と判断した場合、関連する質問を自動生成して深掘り |
| フィードバックループ | 結果を評価し、必要なら修正する | educator が回答をレビューし、難しすぎれば修正を指示 |
| エージェント間連携 | 異なる役割のエージェントが協調する | educator レビュー + パイプラインメタデータ記録 |

---

## 🏗️ 実装ステップ（改訂版）

### ✅ Step 1: ペルソナ修正 + 博士定義の拡充（完了）

- 各エージェントに `expertise` / `cannotHandle` を追加
- `generateExpertResponse` のペルソナ上書き問題を修正
- engineer（テックン博士）を新規追加
- 全博士の名前・ペルソナ・専門領域を再定義

---

### Step 2: オーケストレーター強化（委譲の代替）

**目的**: オーケストレーターの振り分け精度を上げ、そもそも誤振り分けを防ぐ。
definitions.ts の `expertise` / `cannotHandle` を動的にプロンプトに組み込む。

**なぜ委譲をやめたか**:
- オーケストレーターもエキスパートも同じ Gemini モデル
- 同じ情報（質問文）に基づく判断なので、委譲はほぼ発生しない
- 発生するとしたらオーケストレーターの判断ミスのみ
- LLM 呼び出し1回分のコスト（時間+料金）が毎回無駄になる
- → オーケストレーター自体の精度を上げる方が費用対効果が高い

**変更内容**:
- `decideAgent` のプロンプトを、`definitions.ts` の `expertise` から動的に生成
- ハードコードされた専門家リストを廃止
- 各博士の得意/不得意を構造化データとしてプロンプトに注入

**変更ファイル**: `src/lib/agents/core.ts` の `decideAgent`

**確認方法**:
1. 以下の質問で正しい博士が選ばれるかテスト:
   - 「AIって何？」→ engineer
   - 「ゲームはどうやって動くの？」→ engineer
   - 「なぜお腹が鳴るの？」→ educator
   - 「モナリザはなぜ有名？」→ artist
   - 「恐竜はなぜ絶滅した？」→ biologist
   - 「月はなぜ形が変わる？」→ astronomer
2. サーバーログで選択理由が適切か確認

---

### Step 3: educator によるレビュー（フィードバックループ）

**目的**: educator が他のエキスパートの回答を「子供にとって難しすぎないか」
チェックし、必要に応じて修正する。これがフィードバックループの実現。

**これがAIエージェントである理由**:
- educator は回答テキストを受け取り、自律的に「修正が必要か」を判断する
- 修正が必要な場合、具体的な修正版を自分で生成する
- エキスパートとは異なる視点（子供の理解度）で評価する
- → 単なるプロンプトテンプレートではなく、判断 + 行動のループ

**変更内容**:
1. 新しい関数 `educatorReview` を `core.ts` に追加
2. `actions.ts` のパイプラインに組み込み

**変更ファイル**:
- `src/lib/agents/core.ts` — `educatorReview` 関数追加
- `src/app/actions.ts` — パイプラインに educator レビューを組み込み

**確認方法**:
1. 難しい質問でテスト:
   - 「量子力学って何？」→ educator が修正を入れるか
   - 「光合成の仕組みを教えて」→ 専門用語が平易に言い換えられるか
2. 簡単な質問では修正なし:
   - 「犬はなぜしっぽを振るの？」→ approved: true
3. サーバーログで `[Educator] Review: approved=true/false` を確認

---

### Step 4: エキスパートの深掘り提案（ツール使用の実現）

**目的**: エキスパートが回答の最後に「もっと知りたい？」という
次の質問候補を自動生成する。子供の好奇心を連鎖させる。

**これがAIエージェントである理由**:
- エキスパートが回答内容を分析し、関連する次の質問を自律的に生成する
- 質問候補は子供の年齢・興味に応じてパーソナライズされる
- 別の博士の専門領域にまたがる質問も提案できる（エージェント間連携）
- → 単に回答するだけでなく、次のアクションを自分で提案する

**変更内容**:
1. `generateExpertResponse` のレスポンスに `followUpQuestions` を追加
2. 各質問に「どの博士が答えるか」のヒントも含める
3. UI に「もっと聞いてみよう！」ボタンとして表示

**変更ファイル**:
- `src/lib/agents/core.ts` — プロンプト修正
- `src/lib/agents/types.ts` — `FollowUpQuestion` 型追加
- UI コンポーネント（結果表示画面）

**確認方法**:
1. 回答の後に2-3個の次の質問候補が表示されるか
2. 質問候補をタップすると、適切な博士が選ばれて回答が始まるか
3. 質問候補が子供にとって自然で興味を引く内容か

---

### Step 5: パイプライン統合 + メタデータ記録

**目的**: 全ステップを統合し、エージェント間の連携フローを完成させる。
プロセスの履歴を Firestore に記録する。

**変更内容**:
1. `AgentResponse` の `agentPipeline` メタデータを活用
2. `generateResponseAction` で educator レビュー結果を含める
3. `conversation-logger.ts` でメタデータを Firestore に保存
4. 親ダッシュボードで educator のフィードバックを表示

**変更ファイル**:
- `src/app/actions.ts` — パイプライン統合
- `src/lib/conversation-logger.ts` — メタデータ保存
- `src/components/parent/ConversationDetail.tsx` — メタデータ表示

**確認方法**:
1. 通しテスト: 質問 → 博士選択 → 回答 → educator レビュー → 画像 → 音声
2. Firestore に `agentPipeline` メタデータが保存されているか
3. 親ダッシュボードで確認できるか
4. パフォーマンス: educator レビュー追加で +2秒以内

---

## 📊 Before / After 比較

### Before（Step 1 完了時点）

```
質問 → decideAgent()（ハードコード専門家リスト）
         → generateExpertResponse()（ペルソナ反映済み）
           → 画像 → 音声 → 完了
```

- LLM 呼び出し: 2回
- エージェント間連携: なし
- 自律的判断: オーケストレーターのみ
- フィードバックループ: なし
- ツール使用: なし

### After（全 Step 完了後）

```
質問 → decideAgent()（expertise 動的参照で高精度振り分け）
         → generateExpertResponse()（ペルソナ反映 + 深掘り質問生成）
           → educatorReview()（難易度チェック → 必要なら修正）
             → 画像 → 音声 → 完了（メタデータ記録）
```

- LLM 呼び出し: 3回（選択 + 回答 + レビュー）
- エージェント間連携: あり（educator レビュー + 深掘り質問で別博士への橋渡し）
- 自律的判断: あり（educator が修正要否を判断 + エキスパートが次の質問を提案）
- フィードバックループ: あり（educator → エキスパート回答の修正）
- ツール使用: あり（エキスパートが子供の興味に基づき次の質問を動的生成）

---

## 🚀 実装チェックリスト

- [x] Step 1: ペルソナ修正 + 博士定義拡充
- [x] Step 2: オーケストレーター強化（expertise 動的参照）
- [x] Step 3: educator レビュー（フィードバックループ）
- [x] Step 4: 深掘り質問提案（ツール使用）
- [x] Step 5: パイプライン統合 + メタデータ記録
